{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd0d459",
   "metadata": {},
   "source": [
    "# Regression Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c776529a",
   "metadata": {},
   "source": [
    "### Q1: What is Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac77ae",
   "metadata": {},
   "source": [
    "Simple Linear Regression is a statistical technique that models the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line. The relationship is defined by the equation Y = mX + c, where m is the slope and c is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3c14b",
   "metadata": {},
   "source": [
    "### Q2: What are the key assumptions of Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd093e",
   "metadata": {},
   "source": [
    "- Linearity: The relationship between the independent and dependent variable is linear.\n",
    "- Independence: Observations are independent of each other.\n",
    "- Homoscedasticity: Constant variance of residuals across all levels of the independent variable.\n",
    "- Normality: Residuals should be approximately normally distributed.\n",
    "- No multicollinearity: (for multiple regression) Predictors should not be too highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa3125",
   "metadata": {},
   "source": [
    "### Q3: What does the coefficient m represent in the equation Y=mX+c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e82c6d8",
   "metadata": {},
   "source": [
    "The coefficient **m** in the equation Y = mX + c represents the **slope** of the regression line. It shows the rate at which Y changes with respect to X. In other words, it indicates how much Y will increase or decrease when X increases by one unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6abbf8",
   "metadata": {},
   "source": [
    "### Q4: What does the intercept c represent in the equation Y=mX+c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db37a7",
   "metadata": {},
   "source": [
    "The intercept **c** in the equation Y = mX + c represents the **value of Y when X is 0**. It is the point where the regression line crosses the Y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1419c2a9",
   "metadata": {},
   "source": [
    "### Q5: How do we calculate the slope m in Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55aa03f",
   "metadata": {},
   "source": [
    "The slope **m** in Simple Linear Regression is calculated using the formula:\n",
    "\n",
    "m = Σ((X - X̄)(Y - Ȳ)) / Σ((X - X̄)^2)\n",
    "\n",
    "Where X̄ is the mean of X, and Ȳ is the mean of Y. This formula computes the best fit line by minimizing the sum of squared errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba45be0f",
   "metadata": {},
   "source": [
    "### Q6: What is the purpose of the least squares method in Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c9d15c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The cost function in Simple Linear Regression is **Mean Squared Error (MSE)**. It measures the average squared difference between the predicted values and the actual values.\n",
    "Formula:\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "* $y_i$ is the actual value\n",
    "* $\\hat{y}_i$ is the predicted value\n",
    "* $n$ is the number of observations\n",
    "\n",
    "The cost function is used to evaluate how well the linear regression model fits the data. The goal is to minimize the cost function** to find the best-fitting line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed5ef4f",
   "metadata": {},
   "source": [
    "### Q7: How is the coefficient of determination (R²) interpreted in Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918179ab",
   "metadata": {},
   "source": [
    "\n",
    "Gradient Descent is an optimization algorithm used to minimize the cost function in Linear Regression. It updates the model’s parameters (slope and intercept) step by step to reduce the error.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Initialize slope and intercept.\n",
    "2. Calculate the gradient (partial derivatives of the cost function).\n",
    "3. Update the parameters using:\n",
    "\n",
    "   $$\n",
    "   m = m - \\alpha \\cdot \\frac{\\partial \\text{Cost}}{\\partial m}\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   c = c - \\alpha \\cdot \\frac{\\partial \\text{Cost}}{\\partial c}\n",
    "   $$\n",
    "4. Repeat until convergence.\n",
    "\n",
    "Here, $\\alpha$ is the **learning rate**, controlling the size of steps taken toward the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1320b1",
   "metadata": {},
   "source": [
    "### Q8: What is Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930668ed",
   "metadata": {},
   "source": [
    "**Multiple Linear Regression** is an extension of Simple Linear Regression where there are **two or more independent variables** predicting a dependent variable.\n",
    "\n",
    "**Equation:**\n",
    "\n",
    "$$\n",
    "Y = b_0 + b_1X_1 + b_2X_2 + \\dots + b_nX_n\n",
    "$$\n",
    "\n",
    "**Difference:**\n",
    "\n",
    "* Simple Linear Regression uses **1 predictor variable**.\n",
    "* Multiple Linear Regression uses **2 or more predictor variables**.\n",
    "\n",
    "This allows modeling more complex relationships in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cceab1",
   "metadata": {},
   "source": [
    "### Q9: What is the main difference between Simple and Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed60391",
   "metadata": {},
   "source": [
    "**Polynomial Regression** is a form of regression where the relationship between the independent variable and the dependent variable is modeled as an **nth-degree polynomial**.\n",
    "\n",
    "**Equation (for degree 2):**\n",
    "\n",
    "$$\n",
    "Y = b_0 + b_1X + b_2X^2\n",
    "$$\n",
    "\n",
    "**Difference:**\n",
    "\n",
    "* Linear Regression models straight-line relationships.\n",
    "* Polynomial Regression models **curved** relationships (non-linear) while still being a linear model in terms of coefficients.\n",
    "\n",
    "It’s useful when data shows a non-linear trend.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0931eb93",
   "metadata": {},
   "source": [
    "### Q10: What are the key assumptions of Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8610acbe",
   "metadata": {},
   "source": [
    "Simple Linear Regression is a statistical technique that models the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line. The relationship is defined by the equation Y = mX + c, where m is the slope and c is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad043e4",
   "metadata": {},
   "source": [
    "### Q11: What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a6a21",
   "metadata": {},
   "source": [
    "Simple Linear Regression is a statistical technique that models the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line. The relationship is defined by the equation Y = mX + c, where m is the slope and c is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fe3c78",
   "metadata": {},
   "source": [
    "### Q12: How can you improve a Multiple Linear Regression model with high multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce430c53",
   "metadata": {},
   "source": [
    "Simple Linear Regression is a statistical technique that models the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line. The relationship is defined by the equation Y = mX + c, where m is the slope and c is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d88d194",
   "metadata": {},
   "source": [
    "### Q13: What are some common techniques for transforming categorical variables for use in regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7fab17",
   "metadata": {},
   "source": [
    "Simple Linear Regression is a statistical technique that models the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line. The relationship is defined by the equation Y = mX + c, where m is the slope and c is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7b3b8",
   "metadata": {},
   "source": [
    "### Q14: What is the role of interaction terms in Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87781d7a",
   "metadata": {},
   "source": [
    "Simple Linear Regression is a statistical technique that models the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line. The relationship is defined by the equation Y = mX + c, where m is the slope and c is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba3469f",
   "metadata": {},
   "source": [
    "### Q15: How can the interpretation of intercept differ between Simple and Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf47ba",
   "metadata": {},
   "source": [
    "Simple Linear Regression is a statistical technique that models the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line. The relationship is defined by the equation Y = mX + c, where m is the slope and c is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af5fb1",
   "metadata": {},
   "source": [
    "### Q16: What is the significance of the slope in regression analysis, and how does it affect predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3b394",
   "metadata": {},
   "source": [
    "Simple Linear Regression is a statistical technique that models the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line. The relationship is defined by the equation Y = mX + c, where m is the slope and c is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e434e0c",
   "metadata": {},
   "source": [
    "### Q17: How does the intercept in a regression model provide context for the relationship between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfa14c6",
   "metadata": {},
   "source": [
    "Simple Linear Regression is a statistical technique that models the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line. The relationship is defined by the equation Y = mX + c, where m is the slope and c is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6dd2be",
   "metadata": {},
   "source": [
    "### Q18: What are the limitations of using R² as a sole measure of model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bccc776",
   "metadata": {},
   "source": [
    "Simple Linear Regression is a statistical technique that models the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line. The relationship is defined by the equation Y = mX + c, where m is the slope and c is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1a6579",
   "metadata": {},
   "source": [
    "### Q19: How would you interpret a large standard error for a regression coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b75150",
   "metadata": {},
   "source": [
    "Simple Linear Regression is a statistical technique that models the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line. The relationship is defined by the equation Y = mX + c, where m is the slope and c is the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9792a3c4",
   "metadata": {},
   "source": [
    "### Q20: How can heteroscedasticity be identified in residual plots, and why is it important to address it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f6899",
   "metadata": {},
   "source": [
    "- Linearity: The relationship between the independent and dependent variable is linear.\n",
    "- Independence: Observations are independent of each other.\n",
    "- Homoscedasticity: Constant variance of residuals across all levels of the independent variable.\n",
    "- Normality: Residuals should be approximately normally distributed.\n",
    "- No multicollinearity: (for multiple regression) Predictors should not be too highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b0635b",
   "metadata": {},
   "source": [
    "### Q21: What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e61d420",
   "metadata": {},
   "source": [
    "- Linearity: The relationship between the independent and dependent variable is linear.\n",
    "- Independence: Observations are independent of each other.\n",
    "- Homoscedasticity: Constant variance of residuals across all levels of the independent variable.\n",
    "- Normality: Residuals should be approximately normally distributed.\n",
    "- No multicollinearity: (for multiple regression) Predictors should not be too highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bc4994",
   "metadata": {},
   "source": [
    "### Q22: Why is it important to scale variables in Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17a7d51",
   "metadata": {},
   "source": [
    "- Linearity: The relationship between the independent and dependent variable is linear.\n",
    "- Independence: Observations are independent of each other.\n",
    "- Homoscedasticity: Constant variance of residuals across all levels of the independent variable.\n",
    "- Normality: Residuals should be approximately normally distributed.\n",
    "- No multicollinearity: (for multiple regression) Predictors should not be too highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba4768",
   "metadata": {},
   "source": [
    "### Q23: What is polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e9ea65",
   "metadata": {},
   "source": [
    "- Linearity: The relationship between the independent and dependent variable is linear.\n",
    "- Independence: Observations are independent of each other.\n",
    "- Homoscedasticity: Constant variance of residuals across all levels of the independent variable.\n",
    "- Normality: Residuals should be approximately normally distributed.\n",
    "- No multicollinearity: (for multiple regression) Predictors should not be too highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1260aae0",
   "metadata": {},
   "source": [
    "### Q24: How does polynomial regression differ from linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62edf6fb",
   "metadata": {},
   "source": [
    "- Linearity: The relationship between the independent and dependent variable is linear.\n",
    "- Independence: Observations are independent of each other.\n",
    "- Homoscedasticity: Constant variance of residuals across all levels of the independent variable.\n",
    "- Normality: Residuals should be approximately normally distributed.\n",
    "- No multicollinearity: (for multiple regression) Predictors should not be too highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4f3a12",
   "metadata": {},
   "source": [
    "### Q25: When is polynomial regression used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c15ed9b",
   "metadata": {},
   "source": [
    "- Linearity: The relationship between the independent and dependent variable is linear.\n",
    "- Independence: Observations are independent of each other.\n",
    "- Homoscedasticity: Constant variance of residuals across all levels of the independent variable.\n",
    "- Normality: Residuals should be approximately normally distributed.\n",
    "- No multicollinearity: (for multiple regression) Predictors should not be too highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a16575",
   "metadata": {},
   "source": [
    "### Q26: What is the general equation for polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b9cd5d",
   "metadata": {},
   "source": [
    "- Linearity: The relationship between the independent and dependent variable is linear.\n",
    "- Independence: Observations are independent of each other.\n",
    "- Homoscedasticity: Constant variance of residuals across all levels of the independent variable.\n",
    "- Normality: Residuals should be approximately normally distributed.\n",
    "- No multicollinearity: (for multiple regression) Predictors should not be too highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ee133",
   "metadata": {},
   "source": [
    "### Q27: Can polynomial regression be applied to multiple variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93de6287",
   "metadata": {},
   "source": [
    "- Linearity: The relationship between the independent and dependent variable is linear.\n",
    "- Independence: Observations are independent of each other.\n",
    "- Homoscedasticity: Constant variance of residuals across all levels of the independent variable.\n",
    "- Normality: Residuals should be approximately normally distributed.\n",
    "- No multicollinearity: (for multiple regression) Predictors should not be too highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b0ab37",
   "metadata": {},
   "source": [
    "### Q28: What are the limitations of polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af19735",
   "metadata": {},
   "source": [
    "- Linearity: The relationship between the independent and dependent variable is linear.\n",
    "- Independence: Observations are independent of each other.\n",
    "- Homoscedasticity: Constant variance of residuals across all levels of the independent variable.\n",
    "- Normality: Residuals should be approximately normally distributed.\n",
    "- No multicollinearity: (for multiple regression) Predictors should not be too highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b4dd6a",
   "metadata": {},
   "source": [
    "### Q29: What methods can be used to evaluate model fit when selecting the degree of a polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5540f105",
   "metadata": {},
   "source": [
    "- Linearity: The relationship between the independent and dependent variable is linear.\n",
    "- Independence: Observations are independent of each other.\n",
    "- Homoscedasticity: Constant variance of residuals across all levels of the independent variable.\n",
    "- Normality: Residuals should be approximately normally distributed.\n",
    "- No multicollinearity: (for multiple regression) Predictors should not be too highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eac27a2",
   "metadata": {},
   "source": [
    "### Q30: Why is visualization important in polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f139fd9",
   "metadata": {},
   "source": [
    "The coefficient **m** in the equation Y = mX + c represents the **slope** of the regression line. It shows the rate at which Y changes with respect to X. In other words, it indicates how much Y will increase or decrease when X increases by one unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ebabf",
   "metadata": {},
   "source": [
    "### Q31: How is polynomial regression implemented in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae7e1d",
   "metadata": {},
   "source": [
    "The coefficient **m** in the equation Y = mX + c represents the **slope** of the regression line. It shows the rate at which Y changes with respect to X. In other words, it indicates how much Y will increase or decrease when X increases by one unit."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
